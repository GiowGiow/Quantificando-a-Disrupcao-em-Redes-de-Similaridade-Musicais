{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Computing distances with RBF Kernel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### This are the steps to calculate the disruption:\n",
    "1. Extract the feature representation of the audio\n",
    "2. Calculate the \"distance\" for each song against any other song and store this result (in a matrix)\n",
    "3. Use this \"distance\" or \"similarity\" matrix to build the network\n",
    "\n",
    "As the dataset is too big to use in its entirety, we use 1/3 of it (as it is the limit I can use to compute)\n",
    "\n",
    "Ps. When visualizing in EDA it seems that the cut dataset still is a good representation of the complete dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading dataset\n",
    "\n",
    "The first step is to load the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This treated dataset contains the id, artists, song, album name, genres list, popularity, release and duration of each song"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset_size = 30000\n",
    "feat_type = \"transfer_learning\"\n",
    "\n",
    "DATASETS_FOLDER = Path(\"./dataset\")\n",
    "DATAFRAME_PATH = DATASETS_FOLDER / \"cleaned_datasets\" \n",
    "DF_FILENAME = f\"cleaned_song_info_{dataset_size}_entries.csv\"\n",
    "\n",
    "dataframe = pd.read_csv(DATAFRAME_PATH / DF_FILENAME)\n",
    "print(f\"columns: {dataframe.columns}\\nsize: {len(dataframe)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "columns: Index(['id', 'artist', 'song', 'album_name', 'genres', 'spotify_id',\n",
      "       'popularity', 'release', 'danceability', 'energy', 'key', 'mode',\n",
      "       'valence', 'tempo', 'duration_ms'],\n",
      "      dtype='object')\n",
      "size: 109178\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To work with our dataframe a good practice is to make a copy of it so we do not modify the original one"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Copy the dataframe\n",
    "working_dataframe = dataframe.copy(deep=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll have to fix some wrong release dates before we work with this dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Sort the dataframe by release date (as this is going to be important when generating the similarity matrix)\n",
    "dataframe_sorted = working_dataframe.sort_values(by=['release'])\n",
    "dataframe_sorted.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album_name</th>\n",
       "      <th>genres</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5986</th>\n",
       "      <td>3MEb9LZbB80nQ1a8</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>St. James Infirmary</td>\n",
       "      <td>The Complete Hot Five And Hot Seven Recordings...</td>\n",
       "      <td>jazz,blues</td>\n",
       "      <td>7fAa9rz4UmwuB4AGh50Gmp</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>116.508</td>\n",
       "      <td>191867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>DqO2fLBqdVsERa1Z</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>Mack the Knife</td>\n",
       "      <td>The Great American Songbook</td>\n",
       "      <td>jazz,swing,jazz,blues,swing</td>\n",
       "      <td>0RNxWy0PC3AyH4ThH3aGK6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1929</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>88.973</td>\n",
       "      <td>201467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0SI6oF0XlACvZdQT</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>All Of Me</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,vocal jazz,blues,jazz,blues</td>\n",
       "      <td>1LGqJ3nvxpVXDWpEzq4DJD</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>106.994</td>\n",
       "      <td>181440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>1Z7Pb158yANCZ7zN</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>Georgia On My Mind</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,vocal jazz,blues</td>\n",
       "      <td>2JrkYswtbsdxOATXvGTlNf</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>80.172</td>\n",
       "      <td>198560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15581</th>\n",
       "      <td>8rCzU7kVpoJ0Z37D</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>A Fine Romance</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,jazz,blues</td>\n",
       "      <td>2dvty7OgXD51fJGj9Hn0HG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>123.961</td>\n",
       "      <td>171467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id           artist                 song  \\\n",
       "5986   3MEb9LZbB80nQ1a8  Louis Armstrong  St. James Infirmary   \n",
       "24346  DqO2fLBqdVsERa1Z  Louis Armstrong       Mack the Knife   \n",
       "822    0SI6oF0XlACvZdQT   Billie Holiday            All Of Me   \n",
       "2840   1Z7Pb158yANCZ7zN   Billie Holiday   Georgia On My Mind   \n",
       "15581  8rCzU7kVpoJ0Z37D   Billie Holiday       A Fine Romance   \n",
       "\n",
       "                                              album_name  \\\n",
       "5986   The Complete Hot Five And Hot Seven Recordings...   \n",
       "24346                        The Great American Songbook   \n",
       "822    Lady Day: The Complete Billie Holiday On Colum...   \n",
       "2840   Lady Day: The Complete Billie Holiday On Colum...   \n",
       "15581  Lady Day: The Complete Billie Holiday On Colum...   \n",
       "\n",
       "                                 genres              spotify_id  popularity  \\\n",
       "5986                         jazz,blues  7fAa9rz4UmwuB4AGh50Gmp        29.0   \n",
       "24346       jazz,swing,jazz,blues,swing  0RNxWy0PC3AyH4ThH3aGK6        43.0   \n",
       "822    jazz,vocal jazz,blues,jazz,blues  1LGqJ3nvxpVXDWpEzq4DJD        54.0   \n",
       "2840              jazz,vocal jazz,blues  2JrkYswtbsdxOATXvGTlNf        24.0   \n",
       "15581                   jazz,jazz,blues  2dvty7OgXD51fJGj9Hn0HG        24.0   \n",
       "\n",
       "       release  danceability  energy  key  mode  valence    tempo  duration_ms  \n",
       "5986      1928         0.693  0.1820  5.0   0.0    0.588  116.508       191867  \n",
       "24346     1929         0.673  0.3770  0.0   1.0    0.713   88.973       201467  \n",
       "822       1933         0.504  0.0644  2.0   0.0    0.403  106.994       181440  \n",
       "2840      1933         0.489  0.0571  7.0   0.0    0.273   80.172       198560  \n",
       "15581     1933         0.596  0.1820  5.0   1.0    0.711  123.961       171467  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mapping our dataframe to the transfer learning features\n",
    "\n",
    "The transfer learning features have the same ordering of the files of the folder they were extracted, which is not the same as the dataframe now (and the dataframe is now ordered)\n",
    "\n",
    "That means to use them we have to map each song to its corresponding index in the feature dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Loading Transfer Learning Features\n",
    "print(\"Loading Transfer Learning Features...\")\n",
    "transfer_learning_features = np.load(DATASETS_FOLDER / \"input\" / \"extracted_features\" / \"transfer_learning\" / \"features.npy\")\n",
    "print(\"Shape of the transfer learning features: \", np.shape(transfer_learning_features))\n",
    "\n",
    "# Open list of files.txt\n",
    "print(\"Open list of files to make the mapping...\")\n",
    "list_of_files = []\n",
    "with open(DATASETS_FOLDER / \"input\" / \"extracted_features\" / \"transfer_learning\" / \"list_of_files.txt\", \"r\") as files_list:\n",
    "    # split by line ending, each path is a line in this file\n",
    "    list_of_files = files_list.read().split(sep=\"\\n\")\n",
    "\n",
    "# The common information we have is the ID, so we can use it to map to our dataset.\n",
    "print(\"Getting only the IDs from file paths...\")\n",
    "only_ids = []\n",
    "# For all paths in the files list, get only the file name (which is the ID!)\n",
    "for file_name in tqdm(list_of_files):\n",
    "    temp_path = Path(file_name)\n",
    "    only_ids.append(temp_path.stem) # returns only the filename without the extension\n",
    "\n",
    "# Get every ID of our sorted dataframe\n",
    "print(\"Creating the mappings of song to the feature vector indexes \")\n",
    "ids_sorted = dataframe_sorted[\"id\"].to_numpy()\n",
    "\n",
    "# Now we only need to create a new column containing the indexes corresponding to the feature vector\n",
    "mapping_of_indexes = []\n",
    "# Make the mapping of the indexes\n",
    "for song_id in tqdm(ids_sorted):\n",
    "    mapping_of_indexes.append(only_ids.index(song_id))\n",
    "\n",
    "# Adding as a column\n",
    "print(\"Adding the new column with the mapping\")\n",
    "dataframe_sorted[\"mapping_to_fv_index\"] = mapping_of_indexes\n",
    "\n",
    "# Reseting the index so that iloc works\n",
    "print(\"Reseting the index so that iloc works in the sorted dataframe...\")\n",
    "df_sorted_reset_index = dataframe_sorted.reset_index()\n",
    "print(\"All done!\")\n",
    "df_sorted_reset_index.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Transfer Learning Features...\n",
      "Shape of the transfer learning features:  (109269, 160)\n",
      "Open list of files to make the mapping...\n",
      "Getting only the IDs from file paths...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 109269/109269 [00:02<00:00, 52573.12it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating the mappings of song to the feature vector indexes \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:44<00:00, 674.03it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adding the new column with the mapping\n",
      "Reseting the index so that iloc works in the sorted dataframe...\n",
      "All done!\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album_name</th>\n",
       "      <th>genres</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>mapping_to_fv_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5986</td>\n",
       "      <td>3MEb9LZbB80nQ1a8</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>St. James Infirmary</td>\n",
       "      <td>The Complete Hot Five And Hot Seven Recordings...</td>\n",
       "      <td>jazz,blues</td>\n",
       "      <td>7fAa9rz4UmwuB4AGh50Gmp</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>116.508</td>\n",
       "      <td>191867</td>\n",
       "      <td>71045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24346</td>\n",
       "      <td>DqO2fLBqdVsERa1Z</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>Mack the Knife</td>\n",
       "      <td>The Great American Songbook</td>\n",
       "      <td>jazz,swing,jazz,blues,swing</td>\n",
       "      <td>0RNxWy0PC3AyH4ThH3aGK6</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1929</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.3770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>88.973</td>\n",
       "      <td>201467</td>\n",
       "      <td>20950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822</td>\n",
       "      <td>0SI6oF0XlACvZdQT</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>All Of Me</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,vocal jazz,blues,jazz,blues</td>\n",
       "      <td>1LGqJ3nvxpVXDWpEzq4DJD</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>106.994</td>\n",
       "      <td>181440</td>\n",
       "      <td>65996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2840</td>\n",
       "      <td>1Z7Pb158yANCZ7zN</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>Georgia On My Mind</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,vocal jazz,blues</td>\n",
       "      <td>2JrkYswtbsdxOATXvGTlNf</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>80.172</td>\n",
       "      <td>198560</td>\n",
       "      <td>91346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15581</td>\n",
       "      <td>8rCzU7kVpoJ0Z37D</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>A Fine Romance</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>jazz,jazz,blues</td>\n",
       "      <td>2dvty7OgXD51fJGj9Hn0HG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>123.961</td>\n",
       "      <td>171467</td>\n",
       "      <td>108063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                id           artist                 song  \\\n",
       "0   5986  3MEb9LZbB80nQ1a8  Louis Armstrong  St. James Infirmary   \n",
       "1  24346  DqO2fLBqdVsERa1Z  Louis Armstrong       Mack the Knife   \n",
       "2    822  0SI6oF0XlACvZdQT   Billie Holiday            All Of Me   \n",
       "3   2840  1Z7Pb158yANCZ7zN   Billie Holiday   Georgia On My Mind   \n",
       "4  15581  8rCzU7kVpoJ0Z37D   Billie Holiday       A Fine Romance   \n",
       "\n",
       "                                          album_name  \\\n",
       "0  The Complete Hot Five And Hot Seven Recordings...   \n",
       "1                        The Great American Songbook   \n",
       "2  Lady Day: The Complete Billie Holiday On Colum...   \n",
       "3  Lady Day: The Complete Billie Holiday On Colum...   \n",
       "4  Lady Day: The Complete Billie Holiday On Colum...   \n",
       "\n",
       "                             genres              spotify_id  popularity  \\\n",
       "0                        jazz,blues  7fAa9rz4UmwuB4AGh50Gmp        29.0   \n",
       "1       jazz,swing,jazz,blues,swing  0RNxWy0PC3AyH4ThH3aGK6        43.0   \n",
       "2  jazz,vocal jazz,blues,jazz,blues  1LGqJ3nvxpVXDWpEzq4DJD        54.0   \n",
       "3             jazz,vocal jazz,blues  2JrkYswtbsdxOATXvGTlNf        24.0   \n",
       "4                   jazz,jazz,blues  2dvty7OgXD51fJGj9Hn0HG        24.0   \n",
       "\n",
       "   release  danceability  energy  key  mode  valence    tempo  duration_ms  \\\n",
       "0     1928         0.693  0.1820  5.0   0.0    0.588  116.508       191867   \n",
       "1     1929         0.673  0.3770  0.0   1.0    0.713   88.973       201467   \n",
       "2     1933         0.504  0.0644  2.0   0.0    0.403  106.994       181440   \n",
       "3     1933         0.489  0.0571  7.0   0.0    0.273   80.172       198560   \n",
       "4     1933         0.596  0.1820  5.0   1.0    0.711  123.961       171467   \n",
       "\n",
       "   mapping_to_fv_index  \n",
       "0                71045  \n",
       "1                20950  \n",
       "2                65996  \n",
       "3                91346  \n",
       "4               108063  "
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exporting this dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_sorted_reset_index.to_csv(DATASETS_FOLDER / \"input\" / \"csvs\" / f\"sorted_song_info_{len(df_sorted_reset_index)}.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading all features in a feature matrix"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This next step consists in appending the feature vectors in a list, correspoding to the new orderning of the dataset.\n",
    "That way we'll have a 1 to 1 mapping of song to its corresponding feature vector\n",
    "\n",
    "This way we'll have a 2 arrays of feature vectors:\n",
    "- One of MFCC features \n",
    "- One of Transfer Learning features \n",
    "\n",
    "And then they will be ready to use to make a `similarity matrix`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "MFCC_FEATURES_PATH = Path(\"../../dataset/dataset_mfcc\")\n",
    "FILE_ENDING = \"_mfcc.npy\"\n",
    "\n",
    "def get_mfcc_feature_vector(df):\n",
    "    \"\"\" Load and append the feature vector extracted to a variable \n",
    "    This function is slower because every npy is in its separate file, that means heavy IO usage.\n",
    "    \"\"\"\n",
    "    feature_vector = []\n",
    "    ids_list = df['id'].to_list()\n",
    "    print(\"Loading MFCC Features...\")\n",
    "    for song_id in tqdm(ids_list):\n",
    "        file_name = song_id + FILE_ENDING\n",
    "        file_path = MFCC_FEATURES_PATH / file_name\n",
    "        feature_vector.append(np.load(file_path).tolist())\n",
    "    print(\"All done!\")\n",
    "    return feature_vector\n",
    "\n",
    "def get_transfer_learning_feature_vector(df, transfer_learning_feature_vector):\n",
    "    feature_vector = []\n",
    "    print(\"Loading Transfer Learning Features...\")\n",
    "    indexes_list = df['mapping_to_fv_index'].to_list()\n",
    "    for index in tqdm(indexes_list):\n",
    "        feature_vector.append(transfer_learning_feature_vector[index])\n",
    "    print(\"All done!\")\n",
    "    return feature_vector\n",
    "\n",
    "def get_feature_vector(df, feature_type, transfer_learning_feature_vector=None):\n",
    "    if feature_type.lower() == \"mfcc\":\n",
    "        return get_mfcc_feature_vector(df)\n",
    "    elif feature_type.lower() == \"transfer_learning\":\n",
    "        if type(transfer_learning_feature_vector) == None:\n",
    "            raise ValueError(\"transfer_learning_feature_vector cannot be empty!\")\n",
    "        return get_transfer_learning_feature_vector(df, transfer_learning_feature_vector)\n",
    "    else:\n",
    "        raise TypeError(\"Not a valid feature vector type!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#mfcc_feature_vector = get_feature_vector(df_sorted_reset_index, \"mfcc\")\n",
    "#print(np.shape(mfcc_feature_vector))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "transfer_learning_feature_vector = get_feature_vector(df_sorted_reset_index, \"transfer_learning\", transfer_learning_features)\n",
    "print(np.shape(transfer_learning_feature_vector))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Transfer Learning Features...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 30000/30000 [00:00<00:00, 1088628.46it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All done!\n",
      "(30000, 160)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export to avoid computations again"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def export_feature_vector(feature_vector, feat_type):\n",
    "    \"\"\" Saves a feature vector to avoid making this list again \"\"\"\n",
    "    size = np.shape(feature_vector)[0]\n",
    "    np.save( DATASETS_FOLDER / \"input\" / \"feature_vectors\" / feat_type / f\"{feat_type}_feature_vector_{size}_samples.npy\", feature_vector)\n",
    "    print(f\"Saving {feat_type} feature vector of {size} samples complete!\")\n",
    "\n",
    "export_feature_vector(transfer_learning_feature_vector, feat_type=\"transfer_learning\")\n",
    "# export_feature_vector(mfcc_feature_vector, feat_type=\"mfcc\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving transfer_learning feature vector of 30000 samples complete!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing the similarity matrix using the RBF Kernel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "gamma = 0.1\n",
    "similarity_matrix = rbf_kernel(transfer_learning_feature_vector, gamma=gamma)\n",
    "np.fill_diagonal(similarity_matrix, 0) # Just a measure to avoid comparing to itself when generating the network"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def save_similarity_matrix(gamma, matrix, feat_type):\n",
    "    size = np.shape(matrix)[0]\n",
    "    np.save(DATASETS_FOLDER / \"input\" / \"similarity_matrices\" / feat_type / f\"{feat_type}_{size}_samples_{gamma}_gamma.npy\", matrix)\n",
    "    print(f\"Saving similarity matrix of size {size} complete!\")\n",
    "\n",
    "save_similarity_matrix(gamma, similarity_matrix, \"transfer_learning\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving similarity matrix of size 30000 complete!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "a1b5e73f98ecc5046ac4ff6f8b5b285cd0127d9ded83ed20db3ab3b6bcfe82a1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
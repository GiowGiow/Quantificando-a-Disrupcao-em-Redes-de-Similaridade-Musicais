{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Generating the disruption network\n",
    "## And calculating the disruption index\n",
    "\n",
    "One of the most important steps in studying the effect of disruption in songs is actually calculating it based on the similarity matrix we obtained before. That way we use the same list of songs that was used to generate the similarity matrix and use to calculate the disruption score for each song in our dataset. That means that after calculating we can find who were the songs most disruptive in our dataset based on its metadata."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The code below generates a songs disruption network using:\n",
    "1. list of songs (in the same order as the similarity matrix)\n",
    "2. A similarity matrix (ordered by release) so we know that the next song i + 1 is a song released after i\n",
    "3. A similarity threshold that will determine if there is an edge between nodes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "from tqdm import tqdm\n",
    "from networkx.drawing.nx_pylab import draw_networkx"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def generate_network(list_of_songs, similarity_matrix, similarity_threshold=0.80):\n",
    "    \"\"\" Generate a disruption network based on: \n",
    "    If a song has a similarity with another over the threshold than an edge is made to connect both of them.\n",
    "\n",
    "    Args:\n",
    "        1. list of songs (in the same order as the similarity matrix)\n",
    "        2. A similarity matrix (ordered by release) so we know that the next song i + 1 is a song released after i\n",
    "        3. A similarity threshold that will determine if there is an edge between nodes\n",
    "    Returns:\n",
    "        A network as a networkx.DiGraph Object\n",
    "    \"\"\"\n",
    "    slice_index = 0\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for i in tqdm(range(len(list_of_songs))):\n",
    "        edge_count = 0\n",
    "        \n",
    "        G.add_node(i)\n",
    "        \n",
    "        for j in range(i + 1, len(list_of_songs)):\n",
    "            # If there is a high similarity, create an edge between the nodes\n",
    "            if similarity_matrix[i][j] > similarity_threshold:\n",
    "                G.add_edge(j, i)\n",
    "                edge_count += 1\n",
    "        \n",
    "        # If this node does not have a similarity with any other node, then remove the node\n",
    "        if edge_count < 1:\n",
    "            G.remove_node(i)\n",
    "\n",
    "    return G\n",
    "\n",
    "def get_disruption_index_for_nodes(list_of_songs, graph):\n",
    "    \"\"\" Compute the actual disruption indexes for the graph based on the nodes(songs) and its\n",
    "    connections (if its influenced or if it influenced another song) \"\"\"\n",
    "    disruption_info = {}\n",
    "\n",
    "    for i in tqdm(range(len(list_of_songs))):    \n",
    "        if graph.has_node(i):\n",
    "            songs_after = range(i + 1, len(list_of_songs))\n",
    "            song_influences = [edge[1] for edge in graph.edges(i) if edge[1] != i]\n",
    "\n",
    "            ni = 0\n",
    "            nj = 0\n",
    "            nk = 0\n",
    "            \n",
    "            for song_after in songs_after:\n",
    "                consolidating_influence = False\n",
    "                if graph.has_edge(song_after , i):\n",
    "                \n",
    "                    for influence in song_influences:\n",
    "                        if graph.has_edge(song_after, influence):\n",
    "                            consolidating_influence = True\n",
    "                            break\n",
    "                \n",
    "                    if consolidating_influence:\n",
    "                        nj += 1\n",
    "                    else:\n",
    "                        ni += 1\n",
    "                \n",
    "                else:\n",
    "                    for influence in song_influences:\n",
    "                        if graph.has_edge(song_after, influence):\n",
    "                            nk += 1\n",
    "    \n",
    "            disruption_info[list_of_songs.iloc[i]['id']] = [ni, nj, nk, float((ni-nj)) / float((ni+nj+nk))] if (ni + nj + nk) > 0 else [ni, nj, nk, 0]\n",
    "    \n",
    "    return disruption_info\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading our features, matrix and dataframe\n",
    "The first step to build the network it is to load the files generated in prior steps\n",
    "\n",
    "### `Information about the dataset:`\n",
    " - The filtered dataset refers removed the songs that their mp3 had no sound.\n",
    "\n",
    "### `Information about the feature vectors:`\n",
    " -  Features can be both calculated using the MFCC or the concatenation of the features from the transfer learning convnet\n",
    "\n",
    "\n",
    "### `Information about the similarity matrix:`\n",
    "\n",
    "Similarity matrix can have more or less similarities between songs based on the gamma value\n",
    " - Higher means it is more strict\n",
    " - Lesser means that songs that are different will be deemed as similar"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_PATH = Path(\"./dataset\")\n",
    "\n",
    "def load_npy(file_path):\n",
    "    print(f\"Loading: {file_path} ...\")\n",
    "    return np.load(file_path)\n",
    "\n",
    "def load_features_from_file(file_name, feature_type):\n",
    "    if feature_type == \"mfcc\":\n",
    "        return load_npy(DATASET_PATH / \"input\" / \"feature_vectors\" / \"mfcc\" / file_name)\n",
    "    elif feature_type == \"transfer_learning\":\n",
    "        return load_npy(DATASET_PATH / \"input\" / \"feature_vectors\" / \"transfer_learning\" / file_name)\n",
    "    else:\n",
    "        raise TypeError(\"This feature type is not supported\")\n",
    "\n",
    "def load_similarity_matrix(file_name, feature_type):\n",
    "    if feature_type == \"mfcc\":\n",
    "        return load_npy(DATASET_PATH / \"input\" / \"similarity_matrices\" / \"mfcc\" / file_name)\n",
    "    elif feature_type == \"transfer_learning\":\n",
    "        return load_npy(DATASET_PATH / \"input\" / \"similarity_matrices\" / \"transfer_learning\" / file_name)\n",
    "    else:\n",
    "        raise TypeError(\"This feature type is not supported\")\n",
    "\n",
    "def load_dataframe(dataframe_file):\n",
    "    return pd.read_csv(DATASET_PATH / \"input\" / \"csvs\" / dataframe_file)\n",
    "\n",
    "feat_type = \"transfer_learning\"\n",
    "datset_size = 30000\n",
    "gamma = 0.1\n",
    "\n",
    "DF_PATH = f\"sorted_song_info_{datset_size}.csv\"\n",
    "FEATS_PATH = f\"{feat_type}_feature_vector_{datset_size}_samples.npy\"\n",
    "SIMILARITY_MATRIX_PATH = f\"{feat_type}_{datset_size}_samples_{gamma}_gamma.npy\"\n",
    "\n",
    "dataframe = load_dataframe(DF_PATH)\n",
    "features = load_features_from_file(FEATS_PATH, feat_type)\n",
    "similarity_matrix = load_similarity_matrix(SIMILARITY_MATRIX_PATH, feat_type)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading: dataset/input/feature_vectors/transfer_learning/transfer_learning_feature_vector_30000_samples.npy ...\n",
      "Loading: dataset/input/similarity_matrices/transfer_learning/transfer_learning_30000_samples_0.1_gamma.npy ...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we can call the functions defined above to generate the network and calculate the disruption index!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "graph = generate_network(dataframe, similarity_matrix)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  6%|â–Œ         | 1772/30000 [04:08<1:06:02,  7.12it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8edd11aa51e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-147dc13e93a4>\u001b[0m in \u001b[0;36mgenerate_network\u001b[0;34m(list_of_songs, similarity_matrix, similarity_threshold)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_songs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# If there is a high similarity, create an edge between the nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msimilarity_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0medge_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting the graph generated\n",
    "\n",
    "Here we export the generated graph in a way we can analyse it on Gephi later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "disruption_index = get_disruption_index_for_nodes(dataframe, graph)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20000/20000 [1:33:05<00:00,  3.58it/s] \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nx.write_gexf(graph, DATASET_PATH / \"output\" / \"graphs\" / f\"{feat_type}_{len(disruption_index)}_{gamma}.gexf\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some of 29000+ songs used to build the network had no connection with any other, so they didn't even enter the network:\n",
    "\n",
    "```\n",
    "# If this node does not have a similarity with any other node, then remove the node\n",
    "if edge_count < 1:\n",
    "    G.remove_node(i)\n",
    "```\n",
    "\n",
    "That is why we have only 26091 with a disruption index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(disruption_index)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16976"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exporting the disruption index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Store data (serialize)\n",
    "with open(DATASET_PATH / \"output\" / \"disruption_index\" / f'{feat_type}_{len(disruption_index)}_{gamma}.pickle', 'wb') as handle:\n",
    "    pickle.dump(disruption_index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### We should store as a dataframe too"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open(DATASET_PATH / \"output\" / \"disruption_index\" / f'{feat_type}_{len(disruption_index)}_{gamma}.pickle', 'rb') as handle:\n",
    "    loaded_disruption_index = pickle.load(handle)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating the dataframe with the disruption index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "disruption_index_df = pd.DataFrame(loaded_disruption_index).T\n",
    "disruption_index_df.reset_index(inplace=True)\n",
    "disruption_index_df.columns = ['id', 'ni', 'nj', 'nk', 'disruption']\n",
    "disruption_index_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ni</th>\n",
       "      <th>nj</th>\n",
       "      <th>nk</th>\n",
       "      <th>disruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MEb9LZbB80nQ1a8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Z7Pb158yANCZ7zN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHJbjIlp98gVY3Pj</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8rCzU7kVpoJ0Z37D</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1EhoPstBUguE4Btf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    ni   nj   nk  disruption\n",
       "0  3MEb9LZbB80nQ1a8  20.0  0.0  0.0         1.0\n",
       "1  1Z7Pb158yANCZ7zN   1.0  0.0  0.0         1.0\n",
       "2  AHJbjIlp98gVY3Pj   1.0  0.0  0.0         1.0\n",
       "3  8rCzU7kVpoJ0Z37D  55.0  0.0  0.0         1.0\n",
       "4  1EhoPstBUguE4Btf   1.0  0.0  0.0         1.0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Joining song info and song disruption datasets "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "song_info_with_disruption = pd.merge(disruption_index_df, dataframe, on='id')\n",
    "song_info_with_disruption.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ni</th>\n",
       "      <th>nj</th>\n",
       "      <th>nk</th>\n",
       "      <th>disruption</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album_name</th>\n",
       "      <th>...</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>mapping_to_fv_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3MEb9LZbB80nQ1a8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5986</td>\n",
       "      <td>Louis Armstrong</td>\n",
       "      <td>St. James Infirmary</td>\n",
       "      <td>The Complete Hot Five And Hot Seven Recordings...</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.588</td>\n",
       "      <td>116.508</td>\n",
       "      <td>191867</td>\n",
       "      <td>71045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Z7Pb158yANCZ7zN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2840</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>Georgia On My Mind</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273</td>\n",
       "      <td>80.172</td>\n",
       "      <td>198560</td>\n",
       "      <td>91346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHJbjIlp98gVY3Pj</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18091</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>Gloomy Sunday</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>127.089</td>\n",
       "      <td>190800</td>\n",
       "      <td>94072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8rCzU7kVpoJ0Z37D</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15581</td>\n",
       "      <td>Billie Holiday</td>\n",
       "      <td>A Fine Romance</td>\n",
       "      <td>Lady Day: The Complete Billie Holiday On Colum...</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>123.961</td>\n",
       "      <td>171467</td>\n",
       "      <td>108063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1EhoPstBUguE4Btf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2259</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>The Way You Look Tonight</td>\n",
       "      <td>The Essential Fred Astaire</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1935</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.180</td>\n",
       "      <td>75.682</td>\n",
       "      <td>188240</td>\n",
       "      <td>49408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id    ni   nj   nk  disruption  Unnamed: 0  index  \\\n",
       "0  3MEb9LZbB80nQ1a8  20.0  0.0  0.0         1.0           0   5986   \n",
       "1  1Z7Pb158yANCZ7zN   1.0  0.0  0.0         1.0           1   2840   \n",
       "2  AHJbjIlp98gVY3Pj   1.0  0.0  0.0         1.0           2  18091   \n",
       "3  8rCzU7kVpoJ0Z37D  55.0  0.0  0.0         1.0           4  15581   \n",
       "4  1EhoPstBUguE4Btf   1.0  0.0  0.0         1.0           6   2259   \n",
       "\n",
       "            artist                      song  \\\n",
       "0  Louis Armstrong       St. James Infirmary   \n",
       "1   Billie Holiday        Georgia On My Mind   \n",
       "2   Billie Holiday             Gloomy Sunday   \n",
       "3   Billie Holiday            A Fine Romance   \n",
       "4     Fred Astaire  The Way You Look Tonight   \n",
       "\n",
       "                                          album_name  ... popularity release  \\\n",
       "0  The Complete Hot Five And Hot Seven Recordings...  ...       29.0    1928   \n",
       "1  Lady Day: The Complete Billie Holiday On Colum...  ...       24.0    1933   \n",
       "2  Lady Day: The Complete Billie Holiday On Colum...  ...       49.0    1933   \n",
       "3  Lady Day: The Complete Billie Holiday On Colum...  ...       24.0    1933   \n",
       "4                         The Essential Fred Astaire  ...       32.0    1935   \n",
       "\n",
       "   danceability  energy  key  mode  valence    tempo  duration_ms  \\\n",
       "0         0.693  0.1820  5.0   0.0    0.588  116.508       191867   \n",
       "1         0.489  0.0571  7.0   0.0    0.273   80.172       198560   \n",
       "2         0.484  0.0823  7.0   0.0    0.191  127.089       190800   \n",
       "3         0.596  0.1820  5.0   1.0    0.711  123.961       171467   \n",
       "4         0.453  0.1590  2.0   1.0    0.180   75.682       188240   \n",
       "\n",
       "   mapping_to_fv_index  \n",
       "0                71045  \n",
       "1                91346  \n",
       "2                94072  \n",
       "3               108063  \n",
       "4                49408  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "song_info_with_disruption.to_csv(DATASET_PATH / \"output\" / \"csv_with_disruption\" / f\"song_info_with_disruption_{len(song_info_with_disruption)}_feat_{feat_type}_gamma_{gamma}.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "a1b5e73f98ecc5046ac4ff6f8b5b285cd0127d9ded83ed20db3ab3b6bcfe82a1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
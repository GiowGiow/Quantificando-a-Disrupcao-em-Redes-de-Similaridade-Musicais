{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Feature extraction and preparing the data\n",
    "\n",
    "Here we are going to extract the feature vectors of each song using MFCCs and the intermediate layers of the Transfer Learning convnet "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import warnings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Ignore warnings from librosa\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set logging profile\n",
    "logging.basicConfig(filename='extract_features.log', level=logging.INFO)\n",
    "\n",
    "# Set default folder structure\n",
    "DATASET_PATH = \"music4all/\"\n",
    "DATASET_PATH_AUDIOS = DATASET_PATH + \"audios/\"\n",
    "FEATURE_FOLDER = 'dataset_mfcc/'\n",
    "\n",
    "# Number of processes will be the number of cores available\n",
    "n_proc = 8\n",
    "\n",
    "# Dataset audio spec definition\n",
    "SR = 22050 # [Hz] of the songs in Music4All dataset\n",
    "len_src = 30. # [second]\n",
    "ref_n_src = SR * len_src"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if not os.path.exists(FEATURE_FOLDER):\n",
    "    os.mkdir(FEATURE_FOLDER)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def gen_filepaths(df):\n",
    "    \"\"\" Generate file path (column name 'filepath') from given dataframe \"\"\"\n",
    "    for file_name in df['id']:\n",
    "        yield Path(DATASET_PATH_AUDIOS) / file_name + \".mp3\"\n",
    "\n",
    "def open_dataset(path):\n",
    "    return pd.read_csv(path, sep='\\t')\n",
    "\n",
    "# Get mfcc given a dataframe.csv, look for every .mp3 file and extract a\n",
    "# Feature vector based on the mfccs\n",
    "def get_mfcc(filename):    \n",
    "    start = time.time()\n",
    "    csv_filename = '{}.csv'.format(filename)\n",
    "    csv_path = Path(DATASET_PATH) / csv_filename\n",
    "    \n",
    "    df = open_dataset(csv_path)\n",
    "    \n",
    "    # Print some information abouth the dataset\n",
    "    print('{}: Dataframe with size:{}'.format(filename, len(df)))\n",
    "    \n",
    "    # Check if some audio exists\n",
    "    some_audio_file_name = df[\"id\"][0] + \".mp3\"\n",
    "    some_audio_path = Path(DATASET_PATH_AUDIOS) / some_audio_file_name\n",
    "    print(f\"The file {some_audio_file_name} exists? {some_audio_path.exists()}\")\n",
    "    print(f\"Number of Columns: {df.columns}\")\n",
    "    \n",
    "    # Generate file paths\n",
    "    gen_f = gen_filepaths(df)\n",
    "    # Instantiate the lazy generated file paths\n",
    "    paths = list(gen_f)\n",
    "    \n",
    "    # Number of paths to extract features\n",
    "    print(len(paths))\n",
    "    \n",
    "    # Compute the 20 MFCCs with is delta and delta delta derivatives, with their mean and std dev.\n",
    "    Parallel(n_jobs=n_proc, backend='multiprocessing')(delayed(compute_and_save_mfcc_from_path)(path) for path in paths)\n",
    "    \n",
    "    print('MFCC is done! in {:6.4f} sec'.format(time.time() - start))\n",
    "\n",
    "def compute_and_save_mfcc_from_path(path):\n",
    "    print(\"Song \" + path)\n",
    "    logging.info(\"Loading Song: \" + path)\n",
    "    try:\n",
    "        src_zeros = np.zeros(1024) # min length to have 3-frame mfcc's\n",
    "        src, sr = librosa.load(path, sr=SR, duration=30.) # max len: 30s, can be shorter.\n",
    "        \n",
    "        if len(src) < 1024:\n",
    "            src_zeros[:len(src)] = src\n",
    "            src = src_zeros\n",
    "\n",
    "        # Compute the 20 MFCCs for the music in path\n",
    "        logging.info(\"Computing MFCCs for: \" + path)\n",
    "        mfcc = librosa.feature.mfcc(src, SR, n_mfcc=20)\n",
    "        \n",
    "        # Remove the first and last frames as they do not contain information\n",
    "        dmfcc = mfcc[:, 1:] - mfcc[:, :-1]  # delta derivative of the mfcc\n",
    "        ddmfcc = dmfcc[:, 1:] - dmfcc[:, :-1] # delta delta derivative of the mfcc\n",
    "        \n",
    "        \n",
    "        # Compute the feature array with the mean and standard\n",
    "        # deviations of the computed MFCCs (and their derivatives)\n",
    "        feats = np.array(np.concatenate((\n",
    "                            np.mean(mfcc, axis=1), np.std(mfcc, axis=1),\n",
    "                            np.mean(dmfcc, axis=1), np.std(dmfcc, axis=1),\n",
    "                            np.mean(ddmfcc, axis=1), np.std(ddmfcc, axis=1))\n",
    "                            , axis=0))\n",
    "\n",
    "        \n",
    "        # Saving the feature vector\n",
    "        logging.info(\"Saving MFCCs: \" + path)\n",
    "        song_id = Path(path).stem\n",
    "        np.save(os.path.join(FEATURE_FOLDER, f\"{song_id}_mfcc.npy\"), feats)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f'Error occurred!: {e}')\n",
    "        return"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_mfcc(\"id_metadata\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('venv')"
  },
  "interpreter": {
   "hash": "a1b5e73f98ecc5046ac4ff6f8b5b285cd0127d9ded83ed20db3ab3b6bcfe82a1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}